version: '3'  # Versão do Docker Compose

services:  # Definindo os serviços (containers) que serão utilizados

  spark-master:  # Serviço do Master
    image: bitnami/spark:latest  # Imagem Docker do Apache Spark
    container_name: spark-master  # Nome do container
    hostname: spark-master  # Nome do host do container
    networks:
      - spark-network  # Conectando o container à rede 'spark-network'
    ports:
      - "7077:7077"  # Porta RPC (usada para comunicação com os Workers)
      - "8080:8080"  # Porta WebUI (interface de monitoramento do Master)
    volumes:
      - spark-volume:/opt/bitnami/spark/conf  # Monta o volume no diretório de configuração do Spark
    command: ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.master.Master", "--host", "spark-master", "--port", "7077", "--webui-port", "8080"]
    # Comando para iniciar o Master do Spark, definindo o host, porta RPC e a porta da WebUI

  spark-worker-1:  # Serviço do primeiro Worker
    image: bitnami/spark:latest  # Imagem Docker do Apache Spark
    container_name: spark-worker-1  # Nome do container
    hostname: spark-worker-1  # Nome do host do container
    networks:
      - spark-network  # Conectando o container à rede 'spark-network'
    depends_on:
      - spark-master  # O worker depende que o master esteja rodando
    volumes:
      - spark-volume:/opt/bitnami/spark/conf  # Monta o mesmo volume no worker
    command: ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    # Comando para iniciar o Worker do Spark e conectar ao master via RPC (porta 7077)

  spark-worker-2:  # Serviço do segundo Worker
    image: bitnami/spark:latest  # Imagem Docker do Apache Spark
    container_name: spark-worker-2  # Nome do container
    hostname: spark-worker-2  # Nome do host do container
    networks:
      - spark-network  # Conectando o container à rede 'spark-network'
    depends_on:
      - spark-master  # O worker depende que o master esteja rodando
    volumes:
      - spark-volume:/opt/bitnami/spark/conf  # Monta o mesmo volume no worker
    command: ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    # Comando para iniciar o Worker do Spark e conectar ao master via RPC (porta 7077)

  spark-client:  # Novo serviço do Client
    image: bitnami/spark:latest  # Imagem Docker do Apache Spark
    container_name: spark-client  # Nome do container
    hostname: spark-client  # Nome do host do container
    networks:
      - spark-network  # Conectando o container à rede 'spark-network'
    depends_on:
      # O client depende que o master esteja rodando
      - spark-master
      # Os workers devem estar rodando também
      - spark-worker-1
      - spark-worker-2
    volumes:
      - spark-volume:/opt/bitnami/spark/conf  # Monta o mesmo volume compartilhado
      - ./scripts-py:/opt/bitnami/spark/conf/scripts-py  # Monta os scripts Python no container
    environment:
      - SPARK_DRIVER_EXTRA_OPTS=-Divy.cache.dir=/tmp -Divy.home=/tmp  # Configurações adicionais do Spark
    entrypoint: >
      bash -c "
        mkdir -p /opt/bitnami/spark/tmp &&
        touch /opt/bitnami/spark/tmp/nss_passwd &&
        pip install findspark &&
        tail -f /dev/null"
    # O client será acessado manualmente para submeter jobs

networks:  # Definindo a rede que os containers irão usar
  spark-network:
    driver: bridge  # Usando o driver de rede 'bridge' para comunicação entre containers

volumes:  # Definindo o volume compartilhado que os containers irão usar
  spark-volume:
    driver: local  # Indica que o volume é gerenciado localmente pela máquina hospedeira.