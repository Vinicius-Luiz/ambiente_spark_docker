version: '3'

services: # Definição dos serviços do cluster Spark

  spark-master: # Serviço do Master do Spark
    image: bitnami/spark:3.5.2 # Imagem Docker do Apache Spark com a versão especificada
    container_name: spark-master # Nome do container
    hostname: spark-master # Nome do host dentro da rede Docker
    networks:
      - spark-network # Conecta o serviço à rede personalizada 'spark-network'
    ports:
      - "7077:7077" # Porta para comunicação com o Spark Master
      - "8080:8080" # Porta para a interface web do Spark Master
    volumes:
      - spark-volume:/opt/bitnami/spark/conf # Volume compartilhado para persistir configurações do Spark
    command: # Comando para inicializar o Spark Master
      - "/opt/bitnami/spark/bin/spark-class"
      - "org.apache.spark.deploy.master.Master"
      - "--host"
      - "spark-master"
      - "--port"
      - "7077"
      - "--webui-port"
      - "8080"

  spark-worker-1: # Primeiro Spark Worker
    image: bitnami/spark:3.5.2
    container_name: spark-worker-1
    hostname: spark-worker-1
    networks:
      - spark-network
    depends_on:
      - spark-master # Garante que o Master estará disponível antes de iniciar este serviço
    volumes:
      - spark-volume:/opt/bitnami/spark/conf
    command: # Comando para conectar o worker ao Master
      - "/opt/bitnami/spark/bin/spark-class"
      - "org.apache.spark.deploy.worker.Worker"
      - "spark://spark-master:7077" # Endereço do Master

  spark-worker-2: # Segundo Spark Worker (estrutura similar ao primeiro)
    image: bitnami/spark:3.5.2
    container_name: spark-worker-2
    hostname: spark-worker-2
    networks:
      - spark-network
    depends_on:
      - spark-master
    volumes:
      - spark-volume:/opt/bitnami/spark/conf
    command:
      - "/opt/bitnami/spark/bin/spark-class"
      - "org.apache.spark.deploy.worker.Worker"
      - "spark://spark-master:7077"

  spark-client: # Cliente do Spark para submissão de jobs
    image: bitnami/spark:3.5.2
    container_name: spark-client
    hostname: spark-client
    networks:
      - spark-network
    depends_on:
      - spark-master # Garante que o Master estará disponível
      - spark-worker-1 # Garante que o primeiro Worker estará disponível
      - spark-worker-2 # Garante que o segundo Worker estará disponível
    volumes:
      - spark-volume:/opt/bitnami/spark/conf # Volume compartilhado para configurações
      - ./scripts-py:/opt/bitnami/spark/conf/scripts-py # Monta o diretório local 'scripts-py' para armazenar scripts Python
      - ./outputs:/opt/bitnami/spark/conf/output # Monta o diretório local 'outputs' para salvar resultados
    environment: # Variáveis de ambiente adicionais para o cliente
      - SPARK_DRIVER_EXTRA_OPTS=-Divy.cache.dir=/tmp -Divy.home=/tmp # Configurações para cache Maven
    entrypoint: > # Comando inicial do container
      bash -c "
        mkdir -p /opt/bitnami/spark/tmp &&
        touch /opt/bitnami/spark/tmp/nss_passwd &&
        pip install findspark &&
        tail -f /dev/null"

networks: # Configurações da rede Docker
  spark-network: # Rede personalizada para o cluster Spark
    driver: bridge # Tipo de rede (bridge)

volumes: # Configurações de volumes para persistência de dados
  spark-volume: # Volume compartilhado entre Master, Workers e Client
    driver: local # Tipo de volume (local)
