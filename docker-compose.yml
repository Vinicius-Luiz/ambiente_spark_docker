version: '3'  # Versão do Docker Compose

services:  # Definindo os serviços (containers) que serão utilizados

  spark-master:  # Serviço do Master
    image: bitnami/spark:latest  # Imagem Docker do Apache Spark
    container_name: spark-master  # Nome do container
    hostname: spark-master  # Nome do host do container
    networks:
      - spark-network  # Conectando o container à rede 'spark-network'
    ports:
      - "7077:7077"  # Porta RPC (usada para comunicação com os Workers)
      - "8080:8080"  # Porta WebUI (interface de monitoramento do Master)
    command: ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.master.Master", "--host", "spark-master", "--port", "7077", "--webui-port", "8080"]
    # Comando para iniciar o Master do Spark, definindo o host, porta RPC e a porta da WebUI

  spark-worker-1:  # Serviço do primeiro Worker
    image: bitnami/spark:latest  # Imagem Docker do Apache Spark
    container_name: spark-worker-1  # Nome do container
    hostname: spark-worker-1  # Nome do host do container
    networks:
      - spark-network  # Conectando o container à rede 'spark-network'
    depends_on:
      - spark-master  # O worker depende que o master esteja rodando
    command: ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    # Comando para iniciar o Worker do Spark e conectar ao master via RPC (porta 7077)

  spark-worker-2:  # Serviço do segundo Worker
    image: bitnami/spark:latest  # Imagem Docker do Apache Spark
    container_name: spark-worker-2  # Nome do container
    hostname: spark-worker-2  # Nome do host do container
    networks:
      - spark-network  # Conectando o container à rede 'spark-network'
    depends_on:
      - spark-master  # O worker depende que o master esteja rodando
    command: ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    # Comando para iniciar o Worker do Spark e conectar ao master via RPC (porta 7077)

networks:  # Definindo a rede que os containers irão usar
  spark-network:  # Rede personalizada para os containers
    driver: bridge  # Usando o driver de rede 'bridge' para comunicação entre containers
